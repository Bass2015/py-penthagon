{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.arange(8).reshape((4, 2))\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [2, 4],\n",
       "       [4, 6],\n",
       "       [6, 8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(4).reshape(4, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 2,  3],\n",
       "       [ 8, 10],\n",
       "       [18, 21]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa = np.multiply(w, a)\n",
    "wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 34])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 35])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al = wa.sum(axis=0) + b\n",
    "al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 35])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 35])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = np.maximum(0, al)\n",
    "relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = 3 * x ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x7fa0a070c3d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(78732., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 4 * y **3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/zhfgrwvx4r94zbnzqwt6j76h0000gn/T/ipykernel_14100/486760323.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:485.)\n",
      "  y.grad\n"
     ]
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "states = np.arange(20, dtype=np.float32).reshape(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.arange(4).reshape(4,1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.,  9.],\n",
       "        [10., 11., 12., 13., 14.],\n",
       "        [15., 16., 17., 18., 19.]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_t = torch.tensor(states, requires_grad=True)\n",
    "states_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_t = torch.tensor(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 6.],\n",
       "        [12.],\n",
       "        [18.]], grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_taken = states_t.gather(1, actions_t)\n",
    "actions_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.],\n",
       "        [ 36.],\n",
       "        [144.],\n",
       "        [324.]], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = actions_taken **2\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.backward(actions_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,   0.,   0.],\n",
       "        [  0.,  72.,   0.,   0.,   0.],\n",
       "        [  0.,   0., 288.,   0.,   0.],\n",
       "        [  0.,   0.,   0., 648.,   0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_t.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06663611, -0.02188024,  0.05863566,  0.07545803, -0.16402419,\n",
       "        -0.07074134, -0.06466604],\n",
       "       [ 0.04471349, -0.08278085, -0.05594069, -0.0153072 , -0.01844086,\n",
       "        -0.00296326, -0.04318753],\n",
       "       [ 0.13512022, -0.10405465,  0.02528395,  0.07332603, -0.04268725,\n",
       "        -0.0137929 , -0.10638738],\n",
       "       [ 0.03541213,  0.11231263,  0.04135794,  0.12396837, -0.06632223,\n",
       "         0.09482266,  0.00282318],\n",
       "       [-0.0127586 ,  0.052607  , -0.04361942, -0.04765574, -0.00863372,\n",
       "        -0.02964348,  0.00060703],\n",
       "       [-0.16201552, -0.05046922, -0.01770124, -0.03389127,  0.01740537,\n",
       "         0.02722019, -0.02430301],\n",
       "       [-0.02194014,  0.02008729,  0.03144495, -0.11753134,  0.09384697,\n",
       "         0.09208753, -0.13759889]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net.layers[0].weights[0, 0]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent, saving gradients, calculating mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5806745 , 0.60142021, 0.58704945, 0.56904885, 0.60517681,\n",
       "        0.54258573, 0.61743712, 0.61720335, 0.59521046]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dql_model import Network\n",
    "net = Network()\n",
    "input = np.random.randn(4, 75, 75)\n",
    "net.zero_grad(10)\n",
    "output = net(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "net.backward(output, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_grad\n",
    "\n",
    "net.layers[-1].zero_grad(10)\n",
    "\n",
    "\n",
    "if net.layers[-1].inputs.shape[0] == output.shape[0]:\n",
    "    output = output.T\n",
    "dw = output.dot(net.layers[-1].inputs)\n",
    "\n",
    "for e in range(10):\n",
    "    net.layers[-1].weight_gradients[e] = dw.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacer la media de todos los gradientes\n",
    "net.layers[-1].weight_gradients.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = net.layers[-1].backward(output, 0)\n",
    "dl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1600)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl2 = net.layers[-2].backward(dl, 0)\n",
    "dl2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl3 = net.layers[-3].backward(dl2, 0)\n",
    "dl3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 7, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl4 = net.layers[-4].backward(dl3, 0)\n",
    "dl4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 18, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl5 = net.layers[-5].backward(dl4, 0)\n",
    "dl5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 75, 75)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl6 = net.layers[-6].backward(dl5, 0)\n",
    "dl6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70934863, 0.71132165, 0.7443335 , 0.73231912, 0.74903019,\n",
       "        0.74544889, 0.71803037, 0.72243226, 0.72461893]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dql_model import Network\n",
    "net = Network()\n",
    "input = np.random.randn(4, 75, 75)\n",
    "net.zero_grad(10)\n",
    "output = net(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "net.backward(output, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n",
      "fc2--->, W.shape: (512, 9), DY.shape: (1, 9), Inputs: (1, 512)\n",
      "\tDW.shape: (9, 512), Grads.shape: (10, 512, 9)\n",
      "fc1--->, W.shape: (1600, 512), DY.shape: (1, 512), Inputs: (1, 1600)\n",
      "\tDW.shape: (512, 1600), Grads.shape: (10, 1600, 512)\n",
      "conv3--->, W.shape: (64, 64, 3, 3), DY.shape: (64, 5, 5), Inputs: (64, 7, 7)\n",
      "\tDW.shape: (64, 64, 3, 3), Grads.shape: (10, 64, 64, 3, 3)\n",
      "conv2--->, W.shape: (64, 32, 5, 5), DY.shape: (64, 7, 7), Inputs: (32, 18, 18)\n",
      "\tDW.shape: (64, 32, 5, 5), Grads.shape: (10, 64, 32, 5, 5)\n",
      "conv1--->, W.shape: (32, 4, 7, 7), DY.shape: (32, 18, 18), Inputs: (4, 75, 75)\n",
      "\tDW.shape: (32, 4, 7, 7), Grads.shape: (10, 32, 4, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    dl = np.random.normal(0, 1, (output.shape))\n",
    "    net.backward(dl, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-6].bias_gradients.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03010941,  0.02391884, -0.06601707, -0.04852788, -0.05987286,\n",
       "       -0.11834934, -0.0203637 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-6].weights[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optim import SGD\n",
    "\n",
    "optim = SGD(net, 0.1)\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03004637,  0.02401608, -0.06602209, -0.04821476, -0.06029992,\n",
       "       -0.11782329, -0.02075715])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-6].weights[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbf7c05cfd55a56ef01aff8d91874c0af25157022726987367b128e761339d10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
